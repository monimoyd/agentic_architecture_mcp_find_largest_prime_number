from perception import PerceptionResult
from memory import MemoryItem
from typing import List, Optional
from dotenv import load_dotenv
from google import genai
import os

# Optional: import log from agent if shared, else define locally
try:
    from agent import log
except ImportError:
    import datetime
    def log(stage: str, msg: str):
        now = datetime.datetime.now().strftime("%H:%M:%S")
        print(f"[{now}] [{stage}] {msg}")

load_dotenv()
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

def generate_plan(
    perception: PerceptionResult,
    memory_items: List[MemoryItem],
    tool_descriptions: Optional[str] = None
) -> str:
    """Generates a plan (tool call or final answer) using LLM based on structured perception and memory."""

    memory_texts = "\n".join(f"- {m.text}" for m in memory_items) or "None"

    tool_context = f"\nYou have access to the following tools:\n{tool_descriptions}" if tool_descriptions else ""

    prompt = f"""
You are a mathematical reasoning agent that solves problems step by step.
You have access to these tools: {tool_context}

Always follow this loop:

1. Think step-by-step about the problem.
2. If a tool is needed, respond using the format:
   FUNCTION_CALL: tool_name|param1=value1|param2=value2
3. When the final answer is known, respond using:
   FINAL_ANSWER: [your final result]

Guidelines:
- Respond using EXACTLY ONE of the formats above per step.
- Do NOT include extra text, explanation, or formatting.
- Use nested keys (e.g., input.string) and square brackets for lists.
- You can reference these relevant memories:
{memory_texts}
- Respond only with the format given in examples. Do not use any other formats.

Input Summary:
- User input: "{perception.user_input}"
- Intent: {perception.intent}
- Entities: {', '.join(perception.entities)}
- Tool hint: {perception.tool_hint or 'None'}

Examples:
FUNCTION_CALL: find_prime_numbers|input.a=[ 3, 5, 7, 9, 11, 10, 13, 17, 21]
FUNCTION_CALL: find_largest|input.a=[3, 5, 7, 11, 13, 17]
FINAL_ANSWER: [17]


IMPORTANT:
- üö´ Do NOT invent tools. Use only the tools listed below.
- ‚ùå Do NOT repeat function calls with the same parameters.
- ‚ùå Do NOT output unstructured responses.
- üß† Think before each step. Verify intermediate results mentally before proceeding.
- üí• If unsure or no tool fits, skip to FINAL_ANSWER: [unknown]
- ‚úÖ You can take maximum of 12 attempts. Final attempt must be FINAL_ANSWER]
"""

    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt
        )
        raw = response.text.strip()
        log("plan", f"LLM output: {raw}")

        for line in raw.splitlines():
            if line.strip().startswith("FUNCTION_CALL:") or line.strip().startswith("FINAL_ANSWER:"):
                return line.strip()

        return raw.strip()

    except Exception as e:
        log("plan", f"‚ö†Ô∏è Decision generation failed: {e}")
        return "FINAL_ANSWER: [unknown]"
